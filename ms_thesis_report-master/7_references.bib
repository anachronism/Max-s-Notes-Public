%% 07_bibliography:
%  Currently populated with example citations from MQP, replace with actual citations.

%% PAPERS THAT are direct precedents.
@INPROCEEDINGS{paulo_theory_paper, 
author={P. V. R. Ferreira and R. Paffenroth and A. M. Wyglinski and T. M. Hackett and S. G. Bilén and R. C. Reinhart and D. J. Mortensen}, 
booktitle={2017 Cognitive Communications for Aerospace Applications Workshop (CCAA)}, 
title={Multi-objective reinforcement learning-based deep neural networks for cognitive space communications}, 
year={2017}, 
volume={}, 
number={}, 
pages={1-8}, 
keywords={cognitive radio;learning (artificial intelligence);neural nets;resource allocation;satellite communication;software radio;space communication links;telecommunication computing;DVB-S2 standard adaptive transmitter parameters;International Space Station;NASA Glenn Research Center SCaN Testbed;SDR;adaptive radio systems;core cognitive engine proof-of-concept;deep artificial neural networks;future critical space-based missions;hybrid radio resource allocation management control algorithm;machine learning algorithms;multiobjective reinforcement learning;online learning;performance functions;radio parameters;satellite communication channel;software-defined radios;space exploration missions;transmitter parameter adaptation;virtual environment exploration;Artificial neural networks;Learning (artificial intelligence);NASA;Prediction algorithms;Resource management;Space communications;NASA GRC;SCaN Testbed;Satellite communication;artificial intelligence;cognitive radio;machine learning;neural networks;reinforcement learning;space communication}, 
doi={10.1109/CCAAW.2017.8001880}, 
ISSN={}, 
month={June},}


@INPROCEEDINGS{tim_implementation, 
author={T. M. Hackett and S. G. Bilén and P. V. R. Ferreira and A. M. Wyglinski and R. C. Reinhart}, 
booktitle={2017 Cognitive Communications for Aerospace Applications Workshop (CCAA)}, 
title={Implementation of a space communications cognitive engine}, 
year={2017}, 
volume={}, 
number={}, 
pages={1-7}, 
keywords={learning (artificial intelligence);neural nets;software architecture;software libraries;space communication links;DVB-S2 standard;NASA Glenn research center;deep artificial neural networks;modular software architecture;multiobjective reinforcement-learning algorithm;radio-resource-allocation-management controller;real-world radio constraints;software libraries;space communications cognitive engine;Artificial neural networks;Engines;Licenses;NASA;Software libraries;Space vehicles;SCaN Testbed;cognitive engine;machine learning;neural networks;reinforcement learning;space communications}, 
doi={10.1109/CCAAW.2017.8001607}, 
ISSN={}, 
month={June},}

%% Reference papers, Iterative learning:

% PUT THESE IN LATER:
@ARTICLE{NSE_learning_review, 
author={G. Ditzler and M. Roveri and C. Alippi and R. Polikar}, 
journal={IEEE Computational Intelligence Magazine}, 
title={Learning in Nonstationary Environments: A Survey}, 
year={2015}, 
volume={10}, 
number={4}, 
pages={12-25}, 
keywords={Internet of Things;computer aided instruction;mobile handsets;mobile learning;probability;statistical distributions;Internet-of-things technology;aging effects;cyber-physical system;hardware faults;mobile phones;nonadaptive model;nonstationary environments;periodicity effects;probability distribution;sensor networks;software faults;thermal drifts;user habits;Adaptation models;Algorithm design and analysis;Behavioral science;Biological system modeling;Feature extraction;Learning systems;Probability distribution;Sensor phenomena and characterization;Training}, 
doi={10.1109/MCI.2015.2471196}, 
ISSN={1556-603X}, 
month={Nov},}

@INPROCEEDINGS{inc_learning_review, 
author={A. Gepperth and B. Hammer}, 
booktitle={2016 European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning}, 
title={Incremental learning algorithms and applications}, 
year={2016}, 
volume={}, 
number={}, 
pages={357-368}, 
month={April},}
% I-ELM
@ARTICLE{1650244, 
author={}, 
journal={IEEE Transactions on Neural Networks}, 
title={Universal approximation using incremental constructive feedforward networks with random hidden nodes}, 
year={2006}, 
volume={17}, 
number={4}, 
pages={879-892}, 
keywords={learning (artificial intelligence);radial basis function networks;transfer functions;additive nodes;bounded nonconstant piecewise continuous functions;incremental constructive feedforward networks;integrable piecewise continuous functions;neural network theories;nondifferential activation functions;radial basis function hidden nodes;random hidden nodes;single-hidden-layer feedforward networks;threshold networks;universal approximation;Artificial neural networks;Automatic control;Feedforward neural networks;Function approximation;Helium;Joining processes;Machine learning;Neural networks;Radial basis function networks;Support vector machines;Ensemble;feedforward network;incremental extreme learning machine;radial basis function;random hidden nodes;support vector machine;threshold network;universal approximation}, 
doi={10.1109/TNN.2006.875977}, 
ISSN={1045-9227}, 
month={July},}

@article{inc_oselm,
title = "An incremental extreme learning machine for online sequential learning problems",
journal = "Neurocomputing",
volume = "128",
pages = "50 - 58",
year = "2014",
issn = "0925-2312",
doi = "https://doi.org/10.1016/j.neucom.2013.03.055",
url = "http://www.sciencedirect.com/science/article/pii/S0925231213010059",
author = "Lu Guo and Jing-hua Hao and Min Liu",
keywords = "Incremental learning algorithm, Extreme learning machine (ELM), Incremental ELM (IELM), Online sequential ELM (OS-ELM), Fixed size LSSVM (FS-LSSVM)"
}

https://arxiv.org/pdf/1312.6211.pdf
Emperical investigation of catastrophic forgetting.
https://pdfs.semanticscholar.org/f915/4ce80aff79c9ad4106344fcd0c3d1fb0e915.pdf
A look at how orthogonalizing hidden layer weights impacts  a slfn
http://www.ntu.edu.sg/home/egbhuang/pdf/ELM-Randomness-Kernel.pdf
Insight into ELMS
---------------------
Adaptive Neural Nets Filter Using a Recursive Levenberg-Marquardt Search Direction 
Parallel and Separable Recursive LevenbergMarquardt Training Algorithm
OS-ELM
Learn++.NSE, Incremental learning in nonstationary environments with controlled forgetting.

@INPROCEEDINGS{1007781, 
author={R. Polikar and J. Byorick and S. Krause and A. Marino and M. Moreton}, 
booktitle={Neural Networks, 2002. IJCNN '02. Proceedings of the 2002 International Joint Conference on}, 
title={Learn++: a classifier independent incremental learning algorithm for supervised neural networks}, 
year={2002}, 
volume={2}, 
number={}, 
pages={1742-1747}, 
keywords={learning (artificial intelligence);neural nets;Learn++;classifier independent incremental learning algorithm;supervised neural network classifier;supervised neural networks;synergistic expressive power;weak classifiers;Availability;Computer networks;Function approximation;Inference algorithms;Machine learning;Neural networks;Pattern recognition;Power engineering and energy;Power engineering computing;Stability}, 
doi={10.1109/IJCNN.2002.1007781}, 
ISSN={1098-7576}, 
month={},}
% The background in the following paper is useful, but the actual concept isn't what we're trying to do at all.
@INPROCEEDINGS{6033578, 
author={G. Ditzler and R. Polikar}, 
booktitle={The 2011 International Joint Conference on Neural Networks}, 
title={Semi-supervised learning in nonstationary environments}, 
year={2011}, 
volume={}, 
number={}, 
pages={2741-2748}, 
keywords={Gaussian processes;data analysis;learning (artificial intelligence);pattern classification;Gaussian mixture model;data classifier;drifting distribution;learning concept drift;machine learning;nonstationary environment;semisupervised learning;streaming data;unlabelled data;voting weight;Algorithm design and analysis;Classification algorithms;Clustering algorithms;Data models;Testing;Training;Training data;concept drift;ensemble systems;incremental learning;non-stationary environments;unlabeled data}, 
doi={10.1109/IJCNN.2011.6033578}, 
ISSN={2161-4393}, 
month={July},}

%% REFERENCE PAPERS, GANS

@article{gan_overview,
  author    = {Antonia Creswell and
               Tom White and
               Vincent Dumoulin and
               Kai Arulkumaran and
               Biswa Sengupta and
               Anil A. Bharath},
  title     = {Generative Adversarial Networks: An Overview},
  journal   = {CoRR},
  volume    = {abs/1710.07035},
  year      = {2017},
  url       = {http://arxiv.org/abs/1710.07035},
  archivePrefix = {arXiv},
  eprint    = {1710.07035},
  timestamp = {Wed, 01 Nov 2017 19:05:43 +0100},
  biburl    = {http://dblp.org/rec/bib/journals/corr/abs-1710-07035},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

%% MAYBE USEFUL BUT ALSO MAYBE NOT

@ARTICLE{ALI_encdec_inference,
   author = {{Dumoulin}, V. and {Belghazi}, I. and {Poole}, B. and {Mastropietro}, O. and 
    {Lamb}, A. and {Arjovsky}, M. and {Courville}, A.},
    title = "{Adversarially Learned Inference}",
  journal = {ArXiv e-prints},
archivePrefix = "arXiv",
   eprint = {1606.00704},
 primaryClass = "stat.ML",
 keywords = {Statistics - Machine Learning, Computer Science - Learning},
     year = 2016,
    month = jun,
   adsurl = {http://adsabs.harvard.edu/abs/2016arXiv160600704D},
  adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}



