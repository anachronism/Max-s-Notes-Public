# Cross Validation
* Random forest needs few tweaks.
* generally works ok.
* Want to fit the training data (confusion matri and % correct, fscore, etc)
* don't want overly complex model.
* want a function that will generalize well. 
* accuracy increases with complexity on training set (but not on test data). 
* BIC also is also used to stop training.
* w/ test sets, crss validation can be useful. 
  * split data up to N folds (randomly)
  * Be careful with time series data when doing this.
  * leave one for testing, then train on rest.
  * Go through process, changing which fold is test.
  * Small N means that it will happen quickly, less data.
  * large N means more data used to train, but takes longer.
  * Increasing number of folds only increases performance so much ( asymptotic), because the amount of data used in training asymptotes.
* pruning is used to make trees more generalized. 
* CV really needs properly independent data. 
* testing a lot of techniques with cross validation.
  * For each fold going through, each cv will make the "unseen" fold more seen.
  * Read up on train-tune-test methodology instead.
# Bootstrapping
* essentially, draw new samples, get mean.
* Sample with replacement.
  * Repeat, then take sample mean of parameter you care about.
* Large Outliers effects on mean results:
  * the difference between two very large numbers relative to the rest of the dataset mean that they have less impact between, say, 2^100 vs 2^20
## Bootstrap algorithm:
* sample S of size S
For i = 1:N
  draw |s| samples from s w/ replacement.
  Compute something with temp.
  record result
