# Supervised Learning, Q learning
* hard for model to deal with biased data (and hard to boil down to one number)
## Quick look at decision trees
* C4.5:
* Can represent any expression of input attributes
* there is a consistent tree for every training set with one path to each leaf (unless tree is nondeterministic)
* tree did worse with biased data than naive bayes.
* Takes set of cases that are availiable, test on different variables (each branch is a test). 
* Which attributes are good? Typically ones that are more separate (ie not the same results with different splits). Pure groupings.
## Inductive Learning
* Given set of observations, come up with model h that describes them.
* What does "describes" mean? 
* h is the same function as the one that generates them.
  * Bad becauseIn general, do not know which function would be better.
* change h to give good model for both current data, and likely good in the future.
* determining what to generalize is hard.
## Model Fit checking
* R^2
* percent correct
  * kappa (better percent correct)
* BIC, AIC
* AUC, A'
* F score
