# Continuous Search
Review of admissible:
        * admissible means heuristic must be optimistic. 
        * non-admissible just means A* would just return a non-optimal solution.
## Look at 8-queens problem.
        * Hill climbing:
        * Move queen in the same column (they're in different columns) to lowest value square.
        * Only sees small local changes, don't know how we got to any specific location.
        * There's situations where improvements won't make it better, so it won't get to the top. (Local maximum)
        * Local results find local optima frequently.
        * Easy to see it's local with N-queens, but harder for real problems.
        * Many things are NP-hard, no easy solutions. 
## Backing up. Two strategies with dealing with local optima
        * Try again.
        * Don't require improving by maximum. 
  ### 5-queens. Random-restart hill climbing.
        * Expectation Maximization is a random hill climbing algorithm.        
        * Takes a larger amount of time. (Not exactly a factor of number of restarts, sometimes you'll have found the solution before the maximum round. 
        * How to fix for start position number 4 (plateau before peak). 
        * Hill climbing with 8-queens is 14% successful with 3.9 moves.
        * Adding 6 restarts brings it to 65% with 11.5 moves
        * up to 100 sideway moves is 94%, 21 moves
        * Hard to get the last set of improvements.
        * Best next move not necessarily right, instead look at first-choice hill climbing. Useful with continuous problems (pick a move at random). 
        * This is explore vs exploit again.
        
## Simulated Annealing
        * All modifications to hill climbing are about injecting variance into it.
                * So why not explicitly add variance to hill climbing.
        * Look at next state. (If better go there, if not go there with some probability that's decaying exponentially over time. Temperature is the tweakable parameter for the probability). 
        * Generating successor states. 
## Genetic successor states
        * Combine elements of two solutions together to get a better solution.
        * Eg. Look at two different candidates. 
        * Make sure that the candidate solutions are valid answers.
    ### basic, v1:
        * start with k randomly generated states.
                * select two states semi-randomly (weight towards higher fitness)
                * Combine two states to generate two successors.
        * Repeat until population is size N.
        * This generates new population to be parents.
        * fitness is some opposite type function as heuristic.
        * slice points are randomized each merge. 
        * Genetic algorithms may throw away good results.
### v2:        
        * Solve by keeping top solutions. (K2 << k most fit states, called elitism). 
        * Same inner loop as v1.        
        * Population doesn't grow, because it throws away parents.
        * Elitism gives positive monotonic performance.
### v3:
        * Start with k random generated states.
                * select k2 <<k most fit states (elitism)
                * Remove weakest states from population (culling).
                        * Select 2 states semi-randomly.
                               * weight towards better fitness.
                       * Combine 2 states.
                       * randomly change some bits in some of the states (mutation).
                               * Adds variance again.
        * Pick state based on some probability (eg fitness(this solution)/sum(all fitness options)).        
        ### representing candidates. 
        * If the first and last digits have to be the same, can remove last digit and assumes the path would loop. 
                * So pick good candidates lmao.
                * Also, not all children are viable (since some things can repeat). So might have to do some editing.
